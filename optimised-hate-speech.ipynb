{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11686541,"sourceType":"datasetVersion","datasetId":7334972}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Model 1\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/dataset-hate-speech/labeled_data.csv\")\ndf = df.rename(columns={\"class\": \"label\", \"tweet\": \"text\"})\ndf = df[[\"text\", \"label\"]]\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n\n# Vectorize text\nvectorizer = TfidfVectorizer(stop_words=\"english\", max_features=10000)\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\n\n# Train Logistic Regression\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train_vec, y_train)\n\n# Predict & evaluate\ny_pred = model.predict(X_test_vec)\n\n# Predict on new text\ndef predict(text):\n    vec = vectorizer.transform([text])\n    pred = model.predict(vec)[0]\n    label_map = {0: \"hate\", 1: \"offensive\", 2: \"neutral\"}\n    return label_map.get(pred, \"unknown\")\n\n# Test sample\nacc = accuracy_score(y_test, y_pred)\nprint(acc)\nsample_text = \"I hate those people!\"\nprint(\"Prediction:\", predict(sample_text))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-05T14:38:35.476894Z","iopub.execute_input":"2025-05-05T14:38:35.477184Z","iopub.status.idle":"2025-05-05T14:38:37.820494Z","shell.execute_reply.started":"2025-05-05T14:38:35.477164Z","shell.execute_reply":"2025-05-05T14:38:37.819768Z"}},"outputs":[{"name":"stdout","text":"0.893483962073835\nPrediction: hate\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"#Model 2\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sentence_transformers import SentenceTransformer\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/dataset-hate-speech/labeled_data.csv\")\ndf = df.rename(columns={\"class\": \"label\", \"tweet\": \"text\"})\ndf = df[[\"text\", \"label\"]]\ndf[\"label\"] = df[\"label\"].astype(int)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n\n# Load Sentence Transformer model\nembedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # 384-dim vectors, fast\n\n# Encode text\nX_train_vec = embedder.encode(X_train.tolist(), show_progress_bar=True, convert_to_numpy=True)\nX_test_vec = embedder.encode(X_test.tolist(), show_progress_bar=True, convert_to_numpy=True)\n\n# Train classifier\nclf = LogisticRegression(max_iter=1000)\nclf.fit(X_train_vec, y_train)\n\n# Evaluate\ny_pred = clf.predict(X_test_vec)\nprint(classification_report(y_test, y_pred, target_names=[\"hate\", \"offensive\", \"neutral\"]))\n\n# Predict function\ndef predict(text):\n    vec = embedder.encode([text])\n    pred = clf.predict(vec)[0]\n    label_map = {0: \"hate\", 1: \"offensive\", 2: \"neutral\"}\n    return label_map[pred]\n\n# Example prediction\nprint(\"Prediction:\", predict(\"I hate those people.\"))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T14:42:01.523679Z","iopub.execute_input":"2025-05-05T14:42:01.524650Z","iopub.status.idle":"2025-05-05T14:45:46.409205Z","shell.execute_reply.started":"2025-05-05T14:42:01.524619Z","shell.execute_reply":"2025-05-05T14:45:46.408268Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf5479231a4e46fea35fc6fa17edba7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"330a6342e5e14cd7b3781f586de9a121"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76d1d6de599542d787e90ed47c9dc920"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bbcbddf44b2477991d8262032d8ddd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75c0465f6bda410ea92826a480c45915"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f47c78018c452ea36aa16ee4407b76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c99b9b68d30046faaf8d01e30870b13d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a76996d0594440baf0d6416d7dea8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20276ea466b045c28793a127b9ea8abd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ad6fe20117e414baa592c0a9334d3ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd69cfae32c44ee794e84bf61fd225ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/620 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c747f372dc8643468de962b1b7181b38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/155 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b4b8d64cd0a412295bdb06f64c68c8b"}},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        hate       0.46      0.16      0.24       290\n   offensive       0.91      0.96      0.93      3832\n     neutral       0.81      0.79      0.80       835\n\n    accuracy                           0.88      4957\n   macro avg       0.73      0.64      0.66      4957\nweighted avg       0.87      0.88      0.87      4957\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8b222f220634fabbe976d8e62c37907"}},"metadata":{}},{"name":"stdout","text":"Prediction: hate\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"#Model 3\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/dataset-hate-speech/labeled_data.csv\")\ndf = df.rename(columns={\"class\": \"label\", \"tweet\": \"text\"})\ndf = df[[\"text\", \"label\"]]\ndf[\"label\"] = df[\"label\"].astype(int)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n\n# Load Sentence Transformer model\nembedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # 384-dim vectors, fast\n\n# Encode text\nX_train_vec = embedder.encode(X_train.tolist(), show_progress_bar=True, convert_to_numpy=True)\nX_test_vec = embedder.encode(X_test.tolist(), show_progress_bar=True, convert_to_numpy=True)\n\n# Train classifier\n\nweights = compute_class_weight(class_weight='balanced', classes=[0, 1, 2], y=y_train)\nclass_weights = {i: w for i, w in enumerate(weights)}\n\nclf = LogisticRegression(class_weight=class_weights, max_iter=1000)\nclf.fit(X_train_vec, y_train)\n\n# Evaluate\ny_pred = clf.predict(X_test_vec)\nprint(classification_report(y_test, y_pred, target_names=[\"hate\", \"offensive\", \"neutral\"]))\n\n# Predict function\ndef predict(text):\n    vec = embedder.encode([text])\n    pred = clf.predict(vec)[0]\n    label_map = {0: \"hate\", 1: \"offensive\", 2: \"neutral\"}\n    return label_map[pred]\n\n# Example prediction\nprint(\"Prediction:\", predict(\"I hate those people.\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T14:51:44.639322Z","iopub.execute_input":"2025-05-05T14:51:44.639662Z","iopub.status.idle":"2025-05-05T14:55:30.488992Z","shell.execute_reply.started":"2025-05-05T14:51:44.639639Z","shell.execute_reply":"2025-05-05T14:55:30.488325Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/620 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"896d556f8b264437a4291b2b45d2c4ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/155 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"392cc0a8e9d543088e8786d16c9c5021"}},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        hate       0.24      0.69      0.36       290\n   offensive       0.97      0.79      0.87      3832\n     neutral       0.71      0.87      0.78       835\n\n    accuracy                           0.79      4957\n   macro avg       0.64      0.78      0.67      4957\nweighted avg       0.88      0.79      0.82      4957\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c8298ca22bc466d8d38cadfd2f0266c"}},"metadata":{}},{"name":"stdout","text":"Prediction: hate\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}